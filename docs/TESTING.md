# Testing Guide

Comprehensive guide to running and understanding the test suite.

## ğŸš€ Quick Start

```bash
# Activate virtual environment
.\.venv\Scripts\Activate.ps1  # Windows
source .venv/bin/activate      # Linux/Mac

# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_suppliers.py -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html
```

---

## ğŸ“Š Test Suite Overview

The project includes **31 automated tests** across 5 test files:

| Test File | Tests | Coverage |
|-----------|-------|----------|
| `test_suppliers.py` | 8 | Supplier CRUD operations |
| `test_supplier_validation.py` | 6 | Specialty rule enforcement |
| `test_critical_inventory.py` | 7 | Critical inventory reporting |
| `test_api.py` | 5 | Basic API functionality |
| `test_db_connection.py` | 5 | Database schema verification |

---

## ğŸ§ª Test Files Explained

### 1. `test_suppliers.py` - Supplier CRUD Operations

Tests all supplier management endpoints:

- âœ… Creating suppliers with valid data
- âœ… Email validation (invalid formats rejected)
- âœ… Unique name constraint (duplicates rejected)
- âœ… Retrieving all suppliers
- âœ… Retrieving single supplier by ID
- âœ… Updating supplier information
- âœ… Deleting suppliers (with and without toys)
- âœ… Category normalization

**Example Test:**
```python
def test_create_supplier_with_valid_data():
    """Tests creating a supplier with all valid fields."""
    supplier = {
        "name": "Test Supplier",
        "email": "test@supplier.com",
        "specialty": "Action Figures"
    }
    response = client.post("/suppliers", json=supplier)
    assert response.status_code == 200
    assert response.json()["name"] == "Test Supplier"
```

### 2. `test_supplier_validation.py` - The Specialty Rule

Tests the core business rule: suppliers can only provide toys in their specialty.

- âœ… Creating toy with nonexistent supplier fails
- âœ… Creating toy with mismatched specialty fails
- âœ… Creating toy with matching specialty succeeds
- âœ… Updating toy to mismatched supplier fails
- âœ… Updating toy to matching supplier succeeds
- âœ… Deleting supplier with toys fails

**Example Test:**
```python
def test_create_toy_with_mismatched_specialty_fails():
    """Tests that creating a toy with mismatched specialty fails."""
    # Create Dolls supplier
    supplier = client.post("/suppliers", json={
        "name": "Dolls Supplier",
        "email": "dolls@supplier.com",
        "specialty": "Dolls"
    }).json()
    
    # Try to create Action Figures toy (should fail)
    toy = {
        "toy_name": "Action Figure",
        "category": "Action Figures",
        "price": 29.99,
        "in_stock": True,
        "supplier_id": supplier["id"]
    }
    response = client.post("/toys", json=toy)
    assert response.status_code == 400
    assert "specialty" in response.json()["detail"].lower()
```

### 3. `test_critical_inventory.py` - Reporting

Tests the critical inventory report functionality:

- âœ… Empty report when no critical items
- âœ… Out-of-stock items appear in report
- âœ… High-value items (>200) appear in report
- âœ… Items meeting both criteria show combined reason
- âœ… Normal items don't appear in report
- âœ… Supplier information included in report
- âœ… Edge case: price exactly 200 (not critical)

**Example Test:**
```python
def test_out_of_stock_items_appear_in_report():
    """Tests that out of stock items appear in critical inventory."""
    # Create supplier and out-of-stock toy
    supplier = create_test_supplier("Test Supplier", "test@supplier.com", "Test Category")
    toy = create_test_toy("Out of Stock Toy", "Test Category", 50.0, False, supplier["id"])
    
    # Check report
    response = client.get("/reports/critical-inventory")
    assert response.status_code == 200
    items = response.json()
    assert len(items) == 1
    assert items[0]["toy_name"] == "Out of Stock Toy"
    assert "out of stock" in items[0]["reason"].lower()
```

### 4. `test_api.py` - Basic API Functionality

Tests core API operations updated for supplier integration:

- âœ… Health endpoint works
- âœ… GET /toys returns list
- âœ… Toy structure includes supplier info
- âœ… Creating toy with supplier succeeds
- âœ… Creating toy without supplier fails
- âœ… Creating toy with nonexistent supplier fails

### 5. `test_db_connection.py` - Database Schema

Tests database connectivity and schema integrity:

- âœ… Database connection works
- âœ… Toys table exists with correct structure
- âœ… Suppliers table exists with correct structure
- âœ… Foreign key constraint exists
- âœ… Critical inventory view exists

---

## ğŸ”§ Test Fixtures and Cleanup

### Automatic Database Cleanup

The test suite uses **pytest fixtures** defined in `tests/conftest.py` to ensure test isolation:

```python
@pytest.fixture(scope="function", autouse=True)
def cleanup_database():
    """
    Automatically cleans database before and after each test.
    Ensures each test starts with a clean slate.
    """
    # Cleanup before test
    # Run test
    # Cleanup after test
```

**Benefits:**
- âœ… Each test runs independently
- âœ… No data pollution between tests
- âœ… Tests can be run in any order
- âœ… Tests can be run multiple times

### How It Works

1. **Before each test:**
   - Deletes all toys (respecting foreign key constraints)
   - Deletes all suppliers

2. **Test runs** with clean database

3. **After each test:**
   - Cleans up again (optional, but good practice)

### Session-Level Verification

```python
@pytest.fixture(scope="session", autouse=True)
def verify_test_database():
    """
    Runs once at test session start.
    Verifies required tables exist.
    """
```

If tables don't exist, provides helpful error message:
```
Database tables not found. Please run:
  python scripts/create_toys_table.py
  python scripts/create_suppliers_table.py
```

---

## ğŸ¯ Running Specific Tests

### Run Single Test File

```bash
pytest tests/test_suppliers.py -v
```

### Run Single Test Function

```bash
pytest tests/test_suppliers.py::test_create_supplier_with_valid_data -v
```

### Run Tests Matching Pattern

```bash
# All tests with "supplier" in the name
pytest tests/ -k "supplier" -v

# All tests with "validation" in the name
pytest tests/ -k "validation" -v
```

### Run Tests with Output

```bash
# Show print statements
pytest tests/ -v -s

# Show test setup/teardown
pytest tests/ -v --setup-show
```

---

## ğŸ“ˆ Test Coverage

### Generate Coverage Report

```bash
# Terminal report
pytest tests/ --cov=app

# HTML report (opens in browser)
pytest tests/ --cov=app --cov-report=html
open htmlcov/index.html  # Mac/Linux
start htmlcov\index.html  # Windows
```

### Expected Coverage

The test suite provides comprehensive coverage:

- **app/routes.py**: ~95% (all endpoints tested)
- **app/crud.py**: ~90% (all CRUD operations tested)
- **app/schemas.py**: 100% (validation tested)
- **app/models.py**: 100% (used in all tests)

---

## ğŸ› Debugging Failed Tests

### View Detailed Output

```bash
# Verbose output with full error messages
pytest tests/ -vv

# Stop on first failure
pytest tests/ -x

# Drop into debugger on failure
pytest tests/ --pdb
```

### Common Test Failures

#### 1. Database Connection Error

**Error:** `sqlalchemy.exc.OperationalError: could not connect to server`

**Solution:**
```bash
# Ensure database is running
docker-compose up -d
docker ps  # Verify containers are running
```

#### 2. Table Not Found Error

**Error:** `relation "suppliers" does not exist`

**Solution:**
```bash
# Run migrations
python scripts/create_toys_table.py
python scripts/create_suppliers_table.py
```

#### 3. Fixture Not Working

**Error:** Tests fail with duplicate data errors

**Solution:**
```bash
# Manual cleanup
python scripts/clean_test_data.py

# Verify conftest.py exists
ls tests/conftest.py
```

---

## ğŸ§¹ Manual Database Cleanup

If you need to manually clean test data:

```bash
python scripts/clean_test_data.py
```

**Output:**
```
Cleaning test data from database...
âœ“ Deleted 15 toy(s)
âœ“ Deleted 8 supplier(s)

âœ… Database cleaned successfully!
```

---

## ğŸ” Test Best Practices

### Writing New Tests

When adding new tests, follow these patterns:

1. **Use descriptive names:**
   ```python
   def test_create_supplier_with_invalid_email_fails():
       """Tests that invalid email format is rejected."""
   ```

2. **Arrange-Act-Assert pattern:**
   ```python
   def test_example():
       # Arrange: Set up test data
       supplier = {"name": "Test", "email": "test@test.com", "specialty": "Toys"}
       
       # Act: Perform the action
       response = client.post("/suppliers", json=supplier)
       
       # Assert: Verify the result
       assert response.status_code == 200
   ```

3. **Test one thing per test:**
   - Don't combine multiple assertions for different features
   - Keep tests focused and simple

4. **Use helper functions for common operations:**
   ```python
   def create_test_supplier(name, email, specialty):
       """Helper to create a supplier for testing."""
       return client.post("/suppliers", json={
           "name": name,
           "email": email,
           "specialty": specialty
       }).json()
   ```

---

## ğŸ“Š Continuous Integration

### GitHub Actions Example

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: admin
          POSTGRES_PASSWORD: admin123
          POSTGRES_DB: fiverr_db
        ports:
          - 5432:5432
    
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run migrations
        run: |
          python scripts/create_toys_table.py
          python scripts/create_suppliers_table.py
      
      - name: Run tests
        run: pytest tests/ -v --cov=app
```

---

## ğŸ“ Test Scenarios Covered

### Happy Path
- âœ… Creating suppliers and toys with valid data
- âœ… Retrieving data via GET endpoints
- âœ… Updating existing records
- âœ… Generating reports

### Error Handling
- âœ… Invalid email formats
- âœ… Duplicate supplier names
- âœ… Nonexistent references (404s)
- âœ… Business rule violations (specialty mismatch)
- âœ… Foreign key constraints (delete with toys)

### Edge Cases
- âœ… Empty databases
- âœ… Boundary values (price exactly 200)
- âœ… NULL supplier_id for toys
- âœ… Category normalization ("plush" â†’ "Plush")

### Integration
- âœ… End-to-end workflows (create supplier â†’ create toy â†’ generate report)
- âœ… Database triggers
- âœ… Database views
- âœ… Foreign key cascades

---

## ğŸ“š Additional Resources

- **pytest documentation**: https://docs.pytest.org/
- **FastAPI testing**: https://fastapi.tiangolo.com/tutorial/testing/
- **Coverage.py**: https://coverage.readthedocs.io/

---

## âœ… Test Checklist

Before committing code, ensure:

- [ ] All tests pass: `pytest tests/ -v`
- [ ] No new linter errors: Check your IDE
- [ ] Coverage remains high: `pytest tests/ --cov=app`
- [ ] New features have tests
- [ ] Tests are documented with docstrings
- [ ] Database cleanup works properly
